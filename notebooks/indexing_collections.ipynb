{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d00a9e88-1fcb-4af5-9001-cb10c3fc184d",
   "metadata": {},
   "source": [
    "# Qdrant Collection Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60502993-d41b-4532-8c1b-a3be0af8a70b",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "544405c0-e893-4d59-9d5c-7e72c1da90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import (\n",
    "    Distance,\n",
    "    VectorParams,\n",
    "    OptimizersConfig,\n",
    "    ScalarQuantizationConfig,\n",
    "    ScalarType,\n",
    "    ScalarQuantization,\n",
    "    OptimizersConfigDiff,\n",
    "    HnswConfigDiff,\n",
    "    PointStruct,\n",
    "    Filter,\n",
    "    FieldCondition,\n",
    "    MatchValue,\n",
    "    Nested,\n",
    "    NestedCondition,\n",
    "    MatchAny\n",
    ")\n",
    "from sklearn.datasets import make_blobs\n",
    "from ray.util.multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a7a02b-29dd-4abc-90d8-9f070b9498af",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fba11c2-6752-4405-b770-a094c83c5082",
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_HOST = 'localhost'\n",
    "QDRANT_PORT = 6333\n",
    "\n",
    "CLIENT = QdrantClient(url=QDRANT_HOST, port=QDRANT_PORT)\n",
    "\n",
    "COLLECTION_NAME = 'test_collection'\n",
    "\n",
    "NUMBER_OF_FEATURES = 192\n",
    "NUMBER_OF_POINTS = 120_000\n",
    "NUMBER_OF_CENTERS = 25\n",
    "\n",
    "CATEGORIES = ['c1', 'c2', 'c3', 'c4', 'c5', 'c6', ]\n",
    "ASSORTMENT = [\n",
    "    ['a1', 'a3'],\n",
    "    ['a3'],\n",
    "    ['a1', 'a2'],\n",
    "    ['a4'],\n",
    "    ['a2', 'a7'],\n",
    "    ['a2'],\n",
    "    ['a4', 'a2'],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40b7e91-91fb-40e6-8424-10b9052a87ac",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7e56a9-14be-4ca4-8d73-0f371a468916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_points(points: list):\n",
    "    client = QdrantClient(host=QDRANT_HOST,\n",
    "                          port=QDRANT_PORT,\n",
    "                          # grpc_port=6334,\n",
    "                          # prefer_grpc=True,\n",
    "                          timeout=100_000)\n",
    "    client.upsert(\n",
    "        collection_name=COLLECTION_NAME, \n",
    "        points=[PointStruct(id=p['id'], \n",
    "                        vector=p['vector'], \n",
    "                        payload=p['payload']) for p in points]\n",
    "    )\n",
    "\n",
    "\n",
    "def chunks(l: list, n: int):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e877643-8b2d-41dd-bd0b-de0a32551ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_PARAMS = VectorParams(size=NUMBER_OF_FEATURES, distance=Distance.COSINE)\n",
    "QUANTIZATION_CONFIG = ScalarQuantization(scalar=ScalarQuantizationConfig(type=ScalarType.INT8, always_ram=True))\n",
    "OPTIMIZERS_CONFIG = OptimizersConfigDiff(memmap_threshold=20_000, indexing_threshold=1)\n",
    "HNSW_CONFIG = HnswConfigDiff(m=16, ef_construct=100, full_scan_threshold=10_000)\n",
    "\n",
    "\n",
    "def create_index():\n",
    "    field = 'category'\n",
    "    CLIENT.create_payload_index(COLLECTION_NAME, field, 'keyword')\n",
    "    # while CLIENT.get_collection(COLLECTION_NAME).payload_schema[field].points != NUMBER_OF_POINTS:\n",
    "    #     print(f\"Zzzz... Waiting for index on {field} to be created. ({CLIENT.get_collection(COLLECTION_NAME).payload_schema[field].points}/{NUMBER_OF_POINTS}).\")\n",
    "    #     time.sleep(5)\n",
    "\n",
    "    field = 'stores[].id'\n",
    "    CLIENT.create_payload_index(COLLECTION_NAME, field, 'integer')\n",
    "    # while CLIENT.get_collection(COLLECTION_NAME).payload_schema[field].points != NUMBER_OF_POINTS:\n",
    "    #     print(f\"Zzzz... Waiting for index on {field} to be created. ({CLIENT.get_collection(COLLECTION_NAME).payload_schema[field].points}/{NUMBER_OF_POINTS}).\")\n",
    "    #     time.sleep(5)\n",
    "\n",
    "    field = 'stores[].assortment'\n",
    "    CLIENT.create_payload_index(COLLECTION_NAME, field, 'keyword')\n",
    "    # while CLIENT.get_collection(COLLECTION_NAME).payload_schema[field].points != NUMBER_OF_POINTS:\n",
    "    #     print(f\"Zzzz... Waiting for index on {field} to be created. ({CLIENT.get_collection(COLLECTION_NAME).payload_schema[field].points}/{NUMBER_OF_POINTS}).\")\n",
    "    #     time.sleep(5)\n",
    "\n",
    "                             \n",
    "def create_collection(points: list):\n",
    "    CLIENT.recreate_collection(collection_name=COLLECTION_NAME,\n",
    "                               vectors_config=VECTOR_PARAMS,\n",
    "                               shard_number=1,\n",
    "                               on_disk_payload=False,\n",
    "                               optimizers_config=OPTIMIZERS_CONFIG,\n",
    "                               quantization_config=QUANTIZATION_CONFIG)\n",
    "    create_index()\n",
    "    \n",
    "    pool = Pool()\n",
    "    pool.map(upsert_points, chunks(points, 2_000))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    # for chunk in chunks(points, 2_000):\n",
    "    #     upsert_points(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c97308a6-5a22-41b0-b68c-b967b33728e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_collection(query_vector: list, filter=None, n=10) -> float:\n",
    "    durations = []\n",
    "    for _ in range(0, n):\n",
    "        start_time = time.time()\n",
    "        hits = CLIENT.search(collection_name=COLLECTION_NAME,\n",
    "                             query_vector=query_vector,\n",
    "                             query_filter=filter,\n",
    "                             limit=10,\n",
    "                             with_payload=False,\n",
    "                             with_vectors=False)\n",
    "        durations.append(time.time() - start_time)\n",
    "    return sum(durations) / len(durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3c5a356-ee11-41c0-83e1-05f56cc6ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collection_info():\n",
    "    collection_info = CLIENT.get_collection(COLLECTION_NAME)\n",
    "    info = f\"\"\"\n",
    "name: {COLLECTION_NAME} status: {collection_info.status.value}\n",
    "=======================================================================\n",
    "points count: {collection_info.points_count}\n",
    "vector count: {collection_info.vectors_count}\n",
    "indexed vectors count: {collection_info.indexed_vectors_count}\n",
    "\n",
    "collection info: {collection_info}\n",
    "\"\"\"\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e38ec2d-0d3b-440c-b0f3-6cf390c90eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectors(n: int = NUMBER_OF_POINTS) -> list:\n",
    "    vectors, _ = make_blobs(n_samples=n,\n",
    "                            n_features=NUMBER_OF_FEATURES,\n",
    "                            centers=NUMBER_OF_CENTERS,\n",
    "                            cluster_std=2.0,\n",
    "                            center_box=(-5, 5),\n",
    "                            shuffle=True,\n",
    "                            random_state=1)\n",
    "    return [v.tolist() for v in vectors]\n",
    "\n",
    "\n",
    "def create_points(n: int = NUMBER_OF_POINTS) -> list:\n",
    "    vectors = create_vectors(n)\n",
    "    points = []\n",
    "    for i, vector in enumerate(vectors):\n",
    "        point = {\n",
    "            'id': i+1,\n",
    "            'vector': vector,\n",
    "            'payload': {\n",
    "                'category': CATEGORIES[random.randint(0, len(CATEGORIES)-1)],\n",
    "                'stores': [\n",
    "                    {'id': j, 'assortment': ASSORTMENT[random.randint(0, len(ASSORTMENT)-1)]}\n",
    "                for j in range(0, 25)],\n",
    "            }\n",
    "        }\n",
    "        points.append(point)\n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb31cb-459b-4866-8c37-1d7dfc89576e",
   "metadata": {},
   "source": [
    "## Create Collection & Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bfb1fd5-54dc-41f8-bafb-f0fc49434efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 12:25:56,158\tINFO worker.py:1636 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "create_collection(create_points(n=400_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "295184ca-9075-429c-ac9d-5c907e045418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 462000\n",
      "vector count: 462000\n",
      "indexed vectors count: 60000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=462000 indexed_vectors_count=60000 points_count=462000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=338000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=338000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=338000)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_collection_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e213ef7c-7a21-46df-b1ed-80f6590090fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 166000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=166000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 166000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=166000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 166000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=166000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 166000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=166000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 166000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=166000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 166000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=166000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 166000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=166000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 244000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=244000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 244000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=244000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 244000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=244000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 244000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=244000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 244000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=244000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 244000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=244000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 244000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=244000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 244000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=244000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 244000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=244000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 244000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=244000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 244000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=244000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 244000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=244000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 244000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=244000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 244000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=244000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: yellow\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 244000\n",
      "\n",
      "collection info: status=<CollectionStatus.YELLOW: 'yellow'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=244000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000)}\n",
      "\n",
      "\n",
      "name: test_collection status: green\n",
      "=======================================================================\n",
      "points count: 400000\n",
      "vector count: 400000\n",
      "indexed vectors count: 400000\n",
      "\n",
      "collection info: status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=400000 indexed_vectors_count=400000 points_count=400000 segments_count=5 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=192, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None), shard_number=1, replication_factor=1, write_consistency_factor=1, on_disk_payload=False), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=20000, indexing_threshold=1, flush_interval_sec=5, max_optimization_threads=1), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=ScalarQuantization(scalar=ScalarQuantizationConfig(type=<ScalarType.INT8: 'int8'>, quantile=None, always_ram=True))) payload_schema={'category': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000), 'stores[].id': PayloadIndexInfo(data_type=<PayloadSchemaType.INTEGER: 'integer'>, params=None, points=400000), 'stores[].assortment': PayloadIndexInfo(data_type=<PayloadSchemaType.KEYWORD: 'keyword'>, params=None, points=400000)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "while CLIENT.get_collection(COLLECTION_NAME).status.value == 'yellow':\n",
    "    time.sleep(10)\n",
    "    get_collection_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b820ca1-7849-43b0-a7ae-2f50ad2bf178",
   "metadata": {},
   "source": [
    "## Search Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dc7824d-4c02-48c7-acfd-8c6b237dc03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[query_vector] = create_vectors(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fcaece-448c-4094-8502-bf3cad24af26",
   "metadata": {},
   "source": [
    "### W/O Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b66ddbd4-9550-4640-9499-097aa683c545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0050321388244628906"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_collection(query_vector, n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880e4989-e349-40b0-b603-5949a6688538",
   "metadata": {},
   "source": [
    "### Top Level Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28e03cb3-f31b-44ce-9281-36ad5bbd536c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005530626773834229"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter = Filter(must=[FieldCondition(key='category', match=MatchValue(value='c3'))])\n",
    "search_collection(query_vector, filter=filter, n=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6ee77b-88ad-43e9-96cb-360a928f3ebd",
   "metadata": {},
   "source": [
    "### Nested Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d8d9b69-c519-4651-875f-99b201a38e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01533560037612915"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter = Filter(\n",
    "    must=[\n",
    "        NestedCondition(\n",
    "            nested=Nested(\n",
    "                key='stores', \n",
    "                filter=Filter(\n",
    "                    must=[\n",
    "                        FieldCondition(key='id', match=MatchValue(value=4)),\n",
    "                        FieldCondition(key='assortment', match=MatchAny(any=['a1'])),\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "search_collection(query_vector, filter=filter, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05d206-e01d-404c-b3fc-6a04b9eb6027",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
